
input {
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/postgresql-42.7.8.jar"
    jdbc_driver_class => "org.postgresql.Driver"
    jdbc_connection_string => "jdbc:postgresql://${DB_HOST}:${DB_PORT}/${DB_NAME}"
    jdbc_user => "${DB_USER}"
    jdbc_password => "${DB_PASSWORD}"

    # Run every 30 seconds
    schedule => "*/30 * * * * *"

    # Path to your SQL file
    statement_filepath => "/usr/share/logstash/ingest_data/properties_index.sql"

    # Incremental tracking
    use_column_value => true
    tracking_column => "updated_at"
    tracking_column_type => "timestamp"

    clean_run => false
    record_last_run => true

    #store the last processed value in a local file to persist restarts
    last_run_metadata_path => "/usr/share/logstash/data/.logstash_jdbc_last_run_properties"
    jdbc_validate_connection => true
    connection_retry_attempts => 10
    connection_retry_attempts_wait_time => 5
  }
}

filter {
}

output {
  elasticsearch {
    index => "properties"
    hosts => "${ELASTIC_HOSTS}"
    user => "${ELASTIC_USER}"
    password => "${ELASTIC_PASSWORD}"
    ssl_certificate_authorities =>  ["/usr/share/logstash/certs/ca/ca.crt"]
    document_id => "%{id}"
  }
}